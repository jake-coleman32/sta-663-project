\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\@writefile{toc}{\contentsline {section}{\numberline {1}Abstract}{1}{section.1}}
\@writefile{toc}{\contentsline {section}{\numberline {2}Introduction}{1}{section.2}}
\@writefile{toc}{\contentsline {section}{\numberline {3}Background - Hamiltonian Dynamics}{1}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Hamilton's Equations}{1}{subsection.3.1}}
\newlabel{eq:3.1}{{3.1}{2}{Hamilton's Equations}{equation.3.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Potential and Kinetic energy}{2}{subsection.3.2}}
\newlabel{eq:3.2}{{3.2}{2}{Potential and Kinetic energy}{equation.3.2}{}}
\newlabel{eq:3.3}{{3.3}{2}{Potential and Kinetic energy}{equation.3.3}{}}
\newlabel{eq:3.4}{{3.4}{2}{Potential and Kinetic energy}{equation.3.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Discretizing Hamiltons Equation}{2}{subsection.3.3}}
\newlabel{disc}{{3.3}{2}{Discretizing Hamiltons Equation}{subsection.3.3}{}}
\newlabel{eq:3.6}{{3.5}{2}{Discretizing Hamiltons Equation}{equation.3.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Leapfrog Method}{2}{subsubsection.3.3.1}}
\newlabel{eq:3.7}{{3.6}{2}{Leapfrog Method}{equation.3.6}{}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Hamiltonian Monte Carlo}{3}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Probability and the Hamiltonian}{3}{subsection.4.1}}
\newlabel{prob}{{4.1}{3}{Probability and the Hamiltonian}{subsection.4.1}{}}
\newlabel{eq:4.1}{{4.1}{3}{Probability and the Hamiltonian}{equation.4.1}{}}
\newlabel{eq:4.2}{{4.2}{3}{Probability and the Hamiltonian}{equation.4.2}{}}
\newlabel{eq:4.4}{{4.3}{3}{Probability and the Hamiltonian}{equation.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}The Algorithm}{3}{subsection.4.2}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Illustration of HMC and its benefits}{4}{section.5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Trajectories for a two-dimensional problem}{4}{subsection.5.1}}
\newlabel{eq:5.1}{{5.1}{4}{Trajectories for a two-dimensional problem}{equation.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces A trajectory for a 2D Gaussian distribution, simulated using 25 leapfrog steps with a stepsize of 0.25. The initial state for position variable q is $[-1.5,-1.55]^T$. Note how the position coordinate fully explores the space of the highly correlated distribution, while the momentum variables traverse the proposal space.\relax }}{4}{figure.caption.1}}
\providecommand*\caption@xref[2]{\@setref\relax\@undefined{#1}}
\newlabel{Fig:1}{{1}{4}{A trajectory for a 2D Gaussian distribution, simulated using 25 leapfrog steps with a stepsize of 0.25. The initial state for position variable q is $[-1.5,-1.55]^T$. Note how the position coordinate fully explores the space of the highly correlated distribution, while the momentum variables traverse the proposal space.\relax }{figure.caption.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Illustration of Hamiltonian trajectories with increasing stepsize until it reaches critical state.\relax }}{5}{figure.caption.2}}
\newlabel{Fig:2}{{2}{5}{Illustration of Hamiltonian trajectories with increasing stepsize until it reaches critical state.\relax }{figure.caption.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Sampling from a two-dimensional distribution}{5}{subsection.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Twenty iterations from Metropolis (left) and HMC (right) sampling from bivariate Gaussians with .98 correlations. The Metropolis method used a thinning of 20 iterations to compare to HMC with 20 steps per iterations, but HMC still explores the space much better.\relax }}{6}{figure.caption.3}}
\newlabel{Fig:3}{{3}{6}{Twenty iterations from Metropolis (left) and HMC (right) sampling from bivariate Gaussians with .98 correlations. The Metropolis method used a thinning of 20 iterations to compare to HMC with 20 steps per iterations, but HMC still explores the space much better.\relax }{figure.caption.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces The first coordinate of the bivariate Gaussian sampled by the two methods. Metropolis (left) uses a thinning of 20 iterations to compare to HMC, which has 20 leapfrog steps per iteration. It is clear that there is high autocorrelation for Metropolis, even with this thinning, that is not apparent in HMC.\relax }}{6}{figure.caption.4}}
\newlabel{Fig:4}{{4}{6}{The first coordinate of the bivariate Gaussian sampled by the two methods. Metropolis (left) uses a thinning of 20 iterations to compare to HMC, which has 20 leapfrog steps per iteration. It is clear that there is high autocorrelation for Metropolis, even with this thinning, that is not apparent in HMC.\relax }{figure.caption.4}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Efficiency in High dimension}{6}{subsection.5.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Iterations of sampled values for the last coordinate. The autocorrelation for random-walk Metropolis is even more pronounced.\relax }}{7}{figure.caption.5}}
\newlabel{100d_iters}{{5}{7}{Iterations of sampled values for the last coordinate. The autocorrelation for random-walk Metropolis is even more pronounced.\relax }{figure.caption.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Sampled means for all 100 variables - we expect them all to be zero.\relax }}{7}{figure.caption.6}}
\newlabel{100d_means}{{6}{7}{Sampled means for all 100 variables - we expect them all to be zero.\relax }{figure.caption.6}{}}
\bibcite{N}{1}
\bibcite{L}{2}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Sampled standard deviations for all 100 variables - we expect them to lie along the line y=x.\relax }}{8}{figure.caption.7}}
\newlabel{100d_sds}{{7}{8}{Sampled standard deviations for all 100 variables - we expect them to lie along the line y=x.\relax }{figure.caption.7}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Windowed States}{8}{section.6}}
